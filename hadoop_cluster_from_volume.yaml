heat_template_version: ocata

parameters:
  enable_hive:
    type: boolean
    default: False
    description: Enable Hive in Hadoop cluster
  enable_spark:
    type: boolean
    default: False
    description: Enable Spark in Hadoop cluster
  enable_mahout:
    type: boolean
    default: False
    description: Enable Mahout in Hadoop cluster

  flavor:
    type: string
  image:
    type: string
  key_name:
    type: string
  private_net:
    type: string
  public_net:
    type: string
    default: ''
  volume_size:
    type: number
    label: volume size
    description: size of volume (gb)

  slave_count:
    type: number
    label: instances count
    description: Number of instances

conditions:
  has_public_network:
    not:
      equals:
      - {get_param: public_net}
      - ''

resources:
  HadoopSecurityGroup:
    type: OS::Neutron::SecurityGroup
    properties:
      description: Add security group rules for hadoop cluster
      rules:
        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 22
          port_range_max: 22

        - remote_ip_prefix: 0.0.0.0/0
          protocol: icmp

        - remote_ip_prefix: 0.0.0.0/0
          protocol: tcp
          port_range_min: 9000
          port_range_max: 9000

# Hadoop Common Config
  HadoopCommonConfig:
    type: OS::Heat::SoftwareConfig
    properties:
      inputs:
        - name: master_ip
        - name: slave_ip
        - name: core_site_xml
        - name: hdfs_site_xml
        - name: mapred_site_xml
        - name: yarn_site_xml
        - name: workers
      group: ansible
      config: { get_file: ansible/hadoop_common.yaml}

  HadoopMasterCommonDeployment:
    type: OS::Heat::SoftwareDeployment
    properties:
      group: ansible
      input_values:
        - master_ip: {get_attr: [master_server, first_address]}
        - slave_ip: {get_attr: [slave_cluster, slave_ip]}
        - core_site_xml: {get_file: ansible/templates/core-site.j2.xml}
        - hdfs_site_xml: {get_file: ansible/templates/hdfs-site.j2.xml}
        - mapred_site_xml: {get_file: ansible/templates/mapred-site.j2.xml}
        - yarn_site_xml: {get_file: ansible/templates/yarn-site.j2.xml}
        - workers: {get_file: ansible/templates/workers.j2}
      config: {get_resource: HadoopCommonConfig}
      server: {get_resource: master_server}

  HadoopSlaveCommonDeployment:
    type: OS::Heat::SoftwareDeploymentGroup
    properties:
      group: ansible
      input_values:
        - master_ip: {get_attr: [master_server, first_address]}
        - slave_ip: {get_attr: [slave_cluster, slave_ip]}
        - core_site_xml: {get_file: ansible/templates/core-site.j2.xml}
        - hdfs_site_xml: {get_file: ansible/templates/hdfs-site.j2.xml}
        - mapred_site_xml: {get_file: ansible/templates/mapred-site.j2.xml}
        - yarn_site_xml: {get_file: ansible/templates/yarn-site.j2.xml}
        - workers: {get_file: ansible/templates/workers.j2}
      config: {get_resource: HadoopCommonConfig}
      servers: {get_attr: [slave_cluster, attributes, slave_id]}

  HadoopMasterSSHConfig:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ansible
      outputs:
        - name: id_rsa_pub
      config: {get_file: ansible/master_sshkey.yaml}

  HadoopMasterSSHDeployment:
    type: OS::Heat::SoftwareDeployment
    properties:
      group: ansible
      config: {get_resource: HadoopMasterSSHConfig}
      server: {get_resource: master_server}

  HadoopSlaveSSHConfig:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ansible
      inputs:
        - name: id_rsa_pub
      config: {get_file: ansible/slave_sshkey.yaml}

  HadoopSlaveSSHDeployment:
    type: OS::Heat::SoftwareDeploymentGroup
    properties:
      group: ansible
      input_values:
        id_rsa_pub: {get_attr: [HadoopMasterSSHDeployment, id_rsa_pub]}
      config: {get_resource: HadoopSlaveSSHDeployment}
      servers: {get_attr: [slave_cluster, attributes, slave_id]}

  RunHadoopConfig:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        source /root/.bashrc
        /opt/hadoop-2.7.2/sbin/stop-yarn.sh >> /root/run.logs
        /opt/hadoop-2.7.2/sbin/stop-dfs.sh >> /root/run.logs
        /opt/hadoop-2.7.2/sbin/start-dfs.sh >> /root/run.logs
        /opt/hadoop-2.7.2/sbin/start-yarn.sh  >> /root/run.logs

  RunHadoopDeployment:
    type: OS::Heat::SoftwareDeployment
    depends_on:
      - HadoopMasterCommonDeployment
      - HadoopSlaveCommonDeployment
      - HadoopMasterSSHDeployment
      - HadoopSlaveSSHDeployment
    properties:
      input_values:
        slave_ip:
           get_attr: [slave_cluster, attributes, slave_ip]
      config:
        get_resource: RunHadoopConfig
      server:
        get_resource: master_server

# Create Hadoop Cluster
  slave_cluster:
    type: OS::Heat::ResourceGroup
    properties:
      count: { get_param: slave_count }
      resource_def:
        type: slave_from_volume.yaml

  master_server:
    type: OS::Nova::Server
    properties:
      name: hadoop-master
      image:
        get_param: image
      flavor:
        get_param: flavor
      key_name:
        get_param: key_name
      networks:
      - port: {get_resource: server_port}
      user_data_format: SOFTWARE_CONFIG
      block_device_mapping: [{"volume_id": { get_resource: volume_storage },
                              "delete_on_termination": true,
                              "device_name": "vda"}]
  server_port:
    type: OS::Neutron::Port
    properties:
      network_id: { get_param: private_net }
      security_groups: [{ get_resource: HadoopSecurityGroup}]

  server_floating_ip:
    type: OS::Neutron::FloatingIP
    condition: has_public_network
    properties:
      floating_network_id: { get_param: public_net }
      port_id: { get_resource: server_port }

  volume_storage:
   type: OS::Cinder::Volume
   properties:
    size: {get_param: volume_size}
    image: {get_param: image}
# Enable spark, hive, or hadoop

  EnableSpark:
    type: templates/spark.yaml
    condition: {get_param: enable_spark}
    depends_on: RunHadoopDeployment
    properties:
      server: {get_resource: master_server}

  EnableHive:
    type: templates/hive.yaml
    configuration: {get_param: enable_hive}
    depends_on: RunHadoopDeployment
    properties:
      server: {get_resource: master_server}

  EnableMohout:
    type: templates/mahout.yaml
    condition: {get_param: enable_mahout}
    depends_on: RunHadoopDeployment
    properties:
      server: {get_resource: master_server}
